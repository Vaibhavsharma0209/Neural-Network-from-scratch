{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'training_set\\\\training_set\\\\data'\n",
    "TEST_DIR = 'test_set\\\\test_set\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [cat,dog]\n",
    "    #                            [much cat, no dog]\n",
    "    if word_label == 'cat': return [1,0]\n",
    "    #                             [no cat, very doggo]\n",
    "    elif word_label == 'dog': return [0,1]\n",
    "\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 8005/8005 [00:14<00:00, 563.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([i[0] for i in train_data])\n",
    "y = [i[1] for i in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([i[0] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2023/2023 [00:25<00:00, 80.87it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data = process_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array([i[0] for i in test_data])\n",
    "y_test = [i[1] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([i[0] for i in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1024, 8005), (1, 8005), (1024, 2023), (1, 2023))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((x.shape[1]*x.shape[2],x.shape[0]))\n",
    "x_test = x_test.reshape((x_test.shape[1]*x_test.shape[2],x_test.shape[0]))\n",
    "y = y.reshape((1,y.shape[0]))\n",
    "y_test = y_test.reshape((1,y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:, :5000]\n",
    "y_train = y[:, :5000]\n",
    "\n",
    "x_dev = x[:, 5000:]\n",
    "y_dev = y[:, 5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x, n_y = x_train.shape[0], y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dim = [n_x, 200, 100, 50, n_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \n",
    "    A = 1/(1 + np.exp(-Z))\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "\n",
    "    A = np.maximum(0,Z)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_relu(dA, Z):\n",
    "    \n",
    "    dZ = np.array(dA, copy = True)\n",
    "    dZ[Z <= 0 ] = 0\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters(layer_dimensions):\n",
    "    \n",
    "    L = len(layer_dimensions) - 1\n",
    "    parameters = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters['W' + str(l + 1)] = np.random.randn(layer_dimensions[l + 1], layer_dimensions[l]) * np.sqrt(2/layer_dimensions[l])\n",
    "        parameters['b' + str(l + 1)] = np.zeros((layer_dimensions[l + 1], 1))\n",
    "        \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_adam(parameters):\n",
    "    \n",
    "    L = len(parameters) // 2\n",
    "    v = {}\n",
    "    s = {}\n",
    "    for l in range(L):\n",
    "        v['dW' + str(l + 1)] = np.zeros((parameters['W' + str(l + 1)].shape[0], parameters['W' + str(l + 1)].shape[1]))\n",
    "        v['db' + str(l + 1)] = np.zeros((parameters['b' + str(l + 1)].shape[0], parameters['b' + str(l + 1)].shape[1]))\n",
    "        #s[\"dW\" + str(l + 1)] = np.zeros((parameters[\"W\" + str(l + 1)].shape[0], parameters[\"W\" + str(l + 1)].shape[1]))\n",
    "        #s[\"db\" + str(l + 1)] = np.zeros((parameters[\"b\" + str(l + 1)].shape[0], parameters[\"b\" + str(l + 1)].shape[1]))\n",
    "        \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    b1 = parameters['b1']\n",
    "    b2 = parameters['b2']\n",
    "    b3 = parameters['b3']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = relu(Z2)\n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = relu(Z3)\n",
    "    Z4 = np.dot(W4, A3) + b4\n",
    "    A4 = sigmoid(Z4)\n",
    "    \n",
    "    cache = {'Z1':Z1, 'Z2':Z2, 'Z3':Z3, 'Z4':Z4,\n",
    "            'A1':A1, 'A2':A2, 'A3':A3, 'A4':A4}\n",
    "    \n",
    "    return A4, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Y, A4, parameters, lambd):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    W3 = parameters[\"W3\"]\n",
    "    W4 = parameters[\"W4\"]\n",
    "    \n",
    "    regularized_term = (lambd/(2*m)) * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3)) + np.sum(np.square(W4)))\n",
    "\n",
    "    cost = (-1/m) * np.sum((Y * np.log(A4)) + ((1-Y) * np.log(1-A4))) + regularized_term\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, cache, parameters, lambd):\n",
    "   \n",
    "    m = Y.shape[1]\n",
    "    Z1 = cache['Z1']\n",
    "    Z2 = cache['Z2'] \n",
    "    Z3 = cache['Z3']\n",
    "    Z4 = cache['Z4']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    A4 = cache['A4']\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    \n",
    "    \n",
    "    dZ4 = A4 - Y\n",
    "    dW4 = (1/m) * np.dot(dZ4, A3.T) + (lambd * W4/m)\n",
    "    db4 = (1/m) * np.sum(dZ4, axis = 1, keepdims=True)\n",
    "    \n",
    "    dA3 = np.dot(W4.T, dZ4)\n",
    "    dZ3 = d_relu(dA3, Z3)\n",
    "    dW3 = (1/m) * np.dot(dZ3, A2.T) + (lambd * W3/m)\n",
    "    db3 = (1/m) * np.sum(dZ3, axis = 1, keepdims=True)\n",
    "    \n",
    "    dA2 = np.dot(W3.T, dZ3)\n",
    "    dZ2 = d_relu(dA2, Z2)\n",
    "    dW2 = (1/m) * np.dot(dZ2, A1.T) + (lambd * W2/m)\n",
    "    db2 = (1/m) * np.sum(dZ2, axis = 1, keepdims=True) \n",
    "    \n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = d_relu(dA1, Z1)\n",
    "    dW1 = (1/m) * np.dot(dZ1, X.T) + (lambd * W1/m)\n",
    "    db1 = (1/m) * np.sum(dZ1, axis = 1, keepdims=True)    \n",
    "    \n",
    "    grads = {'dW1' : dW1, 'dW2' : dW2, 'dW3' : dW3, 'dW4': dW4, 'db1' : db1, 'db2' : db2, 'db3' : db3, 'db4' : db4}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, v, grads, learning_rate, t, beta1 = 0.9):\n",
    "    \n",
    "    L = len(parameters)//2 \n",
    "    v_corrected = {}\n",
    "    s_corrected = {}\n",
    "    \n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l+1)] = beta1 * v[\"dW\" + str(l+1)] + (1 - beta1) *  grads['dW' + str(l+1)]\n",
    "        v[\"db\" + str(l+1)] = beta1 * v[\"db\" + str(l+1)] + (1 - beta1) *  grads['db' + str(l+1)]\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)] / (1 - (beta1**t))\n",
    "        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)] / (1 - (beta1**t))\n",
    "        \n",
    "        #s[\"dW\" + str(l+1)] = beta2 * s[\"dW\" + str(l+1)] + (1 - beta2) *  ((grads['dW' + str(l+1)])**2)\n",
    "        #s[\"db\" + str(l+1)] = beta2 * s[\"db\" + str(l+1)] + (1 - beta2) *  ((grads['db' + str(l+1)])**2)\n",
    "        \n",
    "        #s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1- (beta2**t))\n",
    "        #s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1- (beta2**t))\n",
    "        \n",
    "        #/ (np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n",
    "        \n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - (learning_rate * v_corrected[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate * v_corrected[\"db\" + str(l+1)])\n",
    "            \n",
    "    return parameters, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layer_dimensions, learning_rate, iterations, lambd, beta1 = 0.9):\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    costs = []\n",
    "    t = 0\n",
    "    \n",
    "    parameters = init_parameters(layer_dimensions)\n",
    "    v = init_adam(parameters)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        A4, cache = forward_propagation(X, parameters)\n",
    "        cost = compute_cost(Y, A4, parameters, lambd)\n",
    "        grads = backward_propagation(X, Y, cache, parameters, lambd)\n",
    "        #parameters = update_parameters(parameters, grads, learning_rate)    'gd'\n",
    "        #parameters, v = update_parameters(parameters, v, grads, learning_rate, beta)\n",
    "        t = t + 1\n",
    "        parameters, v = update_parameters(parameters, v,grads, learning_rate,t, beta1 = 0.9)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(f'Iteration {i}: {cost}')\n",
    "         \n",
    "        costs.append(cost)\n",
    "         \n",
    "    plt.plot(costs)\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: 0.7098377523266454\n",
      "Iteration 100: 0.6896045409349301\n",
      "Iteration 200: 0.6866725819031566\n",
      "Iteration 300: 0.6844395924314765\n",
      "Iteration 400: 0.6824601761032733\n",
      "Iteration 500: 0.6805724534465484\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "para = model(x_train, y_train, layer_dim, 0.01, 2000, lambd = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "a4, _ = forward_propagation(x_train, para)\n",
    "a4_dev, _ = forward_propagation(x_dev, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(A4, Y, parameters):\n",
    "\n",
    "    m = A4.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "\n",
    "    for i in range(0, A4.shape[1]):\n",
    "        if A4[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    print(\"Accuracy: \"  + str(np.sum((p == Y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5968\n",
      "Accuracy: 0.49284525790349415\n"
     ]
    }
   ],
   "source": [
    "preditction_train = predict(a4, y_train, para)\n",
    "prediction_test = predict(a4_dev, y_dev, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train.T, y_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(x_dev.T)\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[668 801]\n",
      " [671 865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.45      0.48      1469\n",
      "           1       0.52      0.56      0.54      1536\n",
      "\n",
      "    accuracy                           0.51      3005\n",
      "   macro avg       0.51      0.51      0.51      3005\n",
      "weighted avg       0.51      0.51      0.51      3005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_dev.T, preds))\n",
    "print(classification_report(y_dev.T, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
